{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kI_NqoE4H2yY"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3pzgCNZvH_pK"
   },
   "source": [
    "## Importing libraries\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Mvl_H0vZq-B"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "ZcgzncjAaNLs",
    "outputId": "c352975b-6e93-4ef1-8247-ee0036a6a99b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uGcZDZurIM3l"
   },
   "source": [
    "## baseline approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6VnA1WDvIRLM"
   },
   "source": [
    "## function to read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVswgwXVZq-G"
   },
   "outputs": [],
   "source": [
    "#This reads CSV a given CSV and stores the data in a list\n",
    "def read_csv(data_path):\n",
    "    file_reader = csv.reader(open(data_path,\"rt\", errors=\"ignore\",encoding=\"utf-8\"), delimiter=',')\n",
    "    sent_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for row in file_reader:\n",
    "        id = row[0]\n",
    "        sent = row[1]\n",
    "        sent_list.append((id,sent))\n",
    "        label_list.append(row[2])\n",
    "    return sent_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ImdMsH_aIYwy"
   },
   "source": [
    "## defining class tagging parsing \n",
    "## sentence split does splitting sentences\n",
    "## tagging NLTK tokenizes sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXQDGfe2Zq-K"
   },
   "outputs": [],
   "source": [
    "class taggingParsing:\n",
    "\n",
    "    def sentenceSplit(self, text):\n",
    "        tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        sentences = tokenizer.tokenize(text)\n",
    "        return sentences\n",
    "\n",
    "    def taggingNLTK(self, text):\n",
    "        tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        sentences = tokenizer.tokenize(text)\n",
    "        for sent in sentences:\n",
    "            text = word_tokenize(sent)\n",
    "            tagged_sent = nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KXmIR94MPtIb"
   },
   "source": [
    "## classify class is there to classify where the sentence has suggection or not. It uses human annotated keyword that are likely to present in the reviews having any suggestions or opinons. On top of it, uses pattern matching and part of speech tagging to classify reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iaC0PvF5Zq-O"
   },
   "outputs": [],
   "source": [
    "def classify(sent_list):\n",
    "\n",
    "    keywords = [\"suggest\",\"recommend\",\"hopefully\",\"go for\",\"request\",\"it would be nice\",\"adding\",\"should come with\",\"should be able\",\"could come with\", \"i need\" , \"we need\",\"needs\", \"would like to\",\"would love to\",\"allow\",\"add\"]\n",
    "\n",
    "    # Goldberg et al.\n",
    "    pattern_strings = [r'.*would\\slike.*if.*', r'.*i\\swish.*', r'.*i\\shope.*', r'.*i\\swant.*', r'.*hopefully.*',\n",
    "                       r\".*if\\sonly.*\", r\".*would\\sbe\\sbetter\\sif.*\", r\".*should.*\", r\".*would\\sthat.*\",\n",
    "                       r\".*can't\\sbelieve.*didn't.*\", r\".*don't\\sbelieve.*didn't.*\", r\".*do\\swant.*\", r\".*i\\scan\\shas.*\"]\n",
    "    compiled_patterns = []\n",
    "    for patt in pattern_strings:\n",
    "        compiled_patterns.append(re.compile(patt))\n",
    "\n",
    "\n",
    "    label_list = []\n",
    "    for sent in sent_list:\n",
    "        tokenized_sent = word_tokenize(sent[1])\n",
    "        tagged_sent = nltk.pos_tag(tokenized_sent)\n",
    "        tags = [i[1] for i in tagged_sent]\n",
    "        label = 0\n",
    "        patt_matched = False\n",
    "        for compiled_patt in compiled_patterns:\n",
    "            joined_sent = \" \".join(tokenized_sent)\n",
    "            matches = compiled_patt.findall(joined_sent)\n",
    "            if len(matches) > 0:\n",
    "                patt_matched = True\n",
    "        keyword_match = any(elem in keywords for elem in tokenized_sent)\n",
    "        \n",
    "        \n",
    "        pos_match = any(elem in ['MD', 'VB'] for elem in tags)\n",
    "\n",
    "    \n",
    "\n",
    "        if patt_matched:\n",
    "            label = 1\n",
    "        elif keyword_match == True:\n",
    "                label = 1\n",
    "        elif pos_match == True:\n",
    "                label = 1    \n",
    "     \n",
    "\n",
    "        label_list.append(label)\n",
    "\n",
    "\n",
    "\n",
    "    return label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jiXdvQ_BZq-S"
   },
   "outputs": [],
   "source": [
    "# sent_list,label_list = read_csv('gdrive/My Drive/NLP task data/V1.4_Training.csv')\n",
    "sent_list,label_list = read_csv('C:\\\\Users\\\\Shishir\\\\data\\\\V1.4_Training.csv')\n",
    "label_list = [int(label) for label in label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6_CrM3V5Zq-W"
   },
   "outputs": [],
   "source": [
    "predicted_label_list = classify(sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3QmfRcOZq-b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "0DS5bX4KZq-j",
    "outputId": "8a6748f5-3d05-4f30-9842-4e713276dc2e"
   },
   "outputs": [],
   "source": [
    "# len(predicted_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ue6e-rf9Zq-p",
    "outputId": "fc0c6217-e0af-4928-c613-14e7c378c3f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.400000000000006\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(sent_list)):\n",
    "    if label_list[i] == predicted_label_list[i]:\n",
    "        count+=1\n",
    "print((float(count)/len(sent_list))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl3lSYbDZq-u",
    "outputId": "664b8919-271d-4276-b4ef-b36c79d3be7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4539"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LfD7TQmrZq-0"
   },
   "outputs": [],
   "source": [
    "c1 = 0\n",
    "c2 = 0\n",
    "for i in range(len(label_list)):\n",
    "    if label_list[i] == 0:\n",
    "        c1+=1\n",
    "    else:\n",
    "        c2+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JliDrpDAZq-4",
    "outputId": "99bf2685-4e5a-4399-8413-fad14160c64f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6415, 2085)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1, c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "26W1OVUyJHPi"
   },
   "source": [
    "## loading glove pretrained model. We would like to use glove pretrained word embedding model as it represents words in vector representation, where values of vector represents contextual similiarity of co-occurences in vector space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-Tq2McwZq--"
   },
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding='utf-8')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uboe5bAWZq_D",
    "outputId": "bc61ddbd-cc37-44de-b9dc-2dc4fc622351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "model = loadGloveModel('C:\\\\Users\\\\Shishir\\\\data\\\\glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f3_2qxRPZq_O",
    "outputId": "8dfde724-05eb-49a4-c540-23e81459841a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.43396 ,  0.73992 ,  0.78403 , -0.41921 ,  0.47901 , -0.90307 ,\n",
       "        0.13821 ,  0.6004  , -0.18415 , -0.62068 , -0.67484 ,  1.2673  ,\n",
       "        0.52699 , -0.11892 ,  0.9452  ,  0.48304 , -0.49922 , -0.98791 ,\n",
       "        0.97262 , -0.98219 ,  0.41451 ,  0.076195,  0.76523 ,  1.1183  ,\n",
       "        1.1039  , -1.2832  , -1.0954  , -0.68419 ,  0.79478 , -1.112   ,\n",
       "        1.8908  ,  0.79092 , -0.74726 ,  0.045625, -0.44904 , -0.26887 ,\n",
       "        0.7335  , -1.1762  ,  0.20768 , -0.45872 ,  1.1217  ,  0.24514 ,\n",
       "        0.39667 ,  0.28376 ,  0.40472 ,  0.6518  ,  0.25236 ,  0.048414,\n",
       "        0.3273  ,  1.1465  ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['please']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Yz1yll-Zq_U",
    "outputId": "0ad3604e-96cf-47f5-dd8a-a5f8865405cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35145  , -0.24155  ,  0.0054776, -0.43396  ,  0.498    ,\n",
       "       -0.15624  ,  0.085152 ,  0.037574 , -0.08182  , -0.11312  ,\n",
       "        0.30311  ,  0.71108  , -0.18012  , -0.14026  ,  0.72316  ,\n",
       "        1.1194   ,  0.54095  , -0.44946  ,  0.64814  , -0.86225  ,\n",
       "       -0.088763 , -0.055229 ,  0.49666  , -0.14049  ,  0.20234  ,\n",
       "       -2.1223   , -0.061711 , -0.18884  ,  0.15737  , -0.52156  ,\n",
       "        3.7028   ,  0.73726  , -1.0739   , -0.63594  , -0.18347  ,\n",
       "       -0.46252  ,  0.36886  ,  0.19455  , -0.068823 , -0.32577  ,\n",
       "       -0.46426  , -0.096529 ,  0.41884  ,  0.53723  , -0.065486 ,\n",
       "        0.14923  , -0.48415  ,  0.46327  , -0.029425 ,  0.34362  ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['should']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p826p8a7KZQl"
   },
   "source": [
    "## function for feature extraction. \n",
    "### We use similiar feature extraction approach as baseline but with some minimal changes.\n",
    "### We are here converting a review into its vector representations. Sentence vector is a weighted sum of words. We give different weights to words in keywords, having a pos tag 'MD' or 'VB' or nothing among them. \n",
    "###  These weights are designed in such a way that the sum of all the weights are equals to 1(basically representing probabilities). \n",
    "### We are giving highest weight to word in keyword, then word in pos tag then others.\n",
    "### We are tried various combinations of these weights and found that weights = {0.8, 0.15, 0.05} for keywords, pos tags, and others respectively is the best combination in terms of highest train and cross validation set accuracy by applying SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pO-7vBWWZq_a"
   },
   "outputs": [],
   "source": [
    "def get_features(sent_list, ):\n",
    "  \n",
    "  \n",
    "  \n",
    "    ## defining keywords that mainly occurs while giving any suggestion or opinion\n",
    "    \n",
    "    keywords = [\"suggest\",\"recommend\",\"hopefully\",\"go\",\"request\",\n",
    "                \"would\",\"be\", \"nice\",\"adding\",\"should\", \"come\",\"able\",\n",
    "                \"could\", \"need\",\"needs\", \"like\",\n",
    "                \"love\",\"allow\",\"add\", \"wish\", \"hope\", \"want\", \"hopefully\", \"better\", \"believe\",\n",
    "                \"if\", \"only\", \"didn't\", \"can\", \"can't\"]\n",
    "\n",
    "\n",
    "    # reading reviews \n",
    "    label_list = []\n",
    "    features = []\n",
    "    for sent in sent_list:\n",
    "        sent_vector = np.zeros(shape=(50,))\n",
    "        tokenized_sent = word_tokenize(sent[1])\n",
    "        tagged_sent = nltk.pos_tag(tokenized_sent)\n",
    "        tags = [i[1] for i in tagged_sent]\n",
    "        label = 0\n",
    "\n",
    "#         keyword_match = any(elem in keywords for elem in tokenized_sent)\n",
    "        for i in range(len(tokenized_sent)):\n",
    "            elem = tokenized_sent[i]\n",
    "            elem = elem.lower()\n",
    "            tag = tagged_sent[i][1]\n",
    "            if model.get(elem) is not None:\n",
    "                # checking for keyword match\n",
    "                if elem in keywords:\n",
    "                    sent_vector+=0.8*model[elem]\n",
    "                # checking if word having pos-tag 'MD' or 'VB'\n",
    "                elif tag in ['MD', 'VB']:\n",
    "                    sent_vector+=0.15*model[elem]\n",
    "                else:\n",
    "                    sent_vector+=0.05*model[elem]\n",
    "        features.append(sent_vector)\n",
    "    features = np.array(features)\n",
    "    return features\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjDkQjHiXLB5"
   },
   "source": [
    "### reading training data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jqmsmdkZq_g"
   },
   "outputs": [],
   "source": [
    "sent_list,label_list = read_csv('C:\\\\Users\\\\Shishir\\\\data\\\\V1.4_Training.csv')\n",
    "features = get_features(sent_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ue8w2UyXXk_O"
   },
   "source": [
    "### dumping features into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcY2E5NTZq_l"
   },
   "outputs": [],
   "source": [
    "# with open('features', 'wb') as file:\n",
    "#     pickle.dump(features, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4nqRnezLYIIs"
   },
   "source": [
    "### loading features from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ShnagaZVZq_q"
   },
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Shishir\\\\data\\\\features', 'rb') as file:\n",
    "    features = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ASP5q1AGZq_u"
   },
   "outputs": [],
   "source": [
    "label_list = np.array([int(label) for label in label_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0kHmFtBBYPzz"
   },
   "source": [
    "### using SVM classifier for classifying reviews.\n",
    "### We are using SVM classifier as it is good to detect non linear decision boundaries and it performs well in case of very high dimentional data.\n",
    "### We used 'rbf' kernel as it works well to draw non linear decision boundaries in higher dimentional space.\n",
    "### here parameter C is regularization parameter.\n",
    "### we have tried different values C and found that C=20.0 will be that best value on terms of accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBJ-6fJmZq_z",
    "outputId": "8b4b0b38-68f7-4667-8089-4b650a75b3ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shishir\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    " classifier = svm.SVC(C=20.0, kernel='rbf').fit(features, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msa755TtZq_3",
    "outputId": "38a4e097-c2eb-45ae-bec9-7cb07812fb98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.9315294117647058\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = classifier.predict(features)\n",
    "print('train accuracy: ', accuracy_score(label_list, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCUdo_-AZq_8",
    "outputId": "b07ef21a-a36b-4e1d-e069-c854b29ef830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7918\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for i in range(len(predicted_labels)):\n",
    "    if predicted_labels[i] == label_list[i]:\n",
    "        c+=1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PLqDfkffZrAB",
    "outputId": "ee82621e-7af5-4e55-d9af-42365b08ddaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0myV2JaTZrAF"
   },
   "outputs": [],
   "source": [
    "test_sent_list,test_label_list = read_csv('C:\\\\Users\\\\Shishir\\\\data\\\\SubtaskA_Trial_Test_Labeled.csv')\n",
    "test_sent_list = test_sent_list[1:]\n",
    "test_label_list = test_label_list[1:]\n",
    "test_label_list = np.array([int(label) for label in test_label_list])\n",
    "test_features = get_features(test_sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sT4Bx2k9ZrAJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V1uWkMh8ZrAM"
   },
   "outputs": [],
   "source": [
    "predicted_labels_test= classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9X4NXZpZrAQ",
    "outputId": "46e4204c-8e82-4605-f11e-67812aaa8b56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SoMCbW1IZrAW",
    "outputId": "b090e216-59f7-4cec-f963-2d826648f868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592\n",
      "424\n"
     ]
    }
   ],
   "source": [
    "print(len(test_sent_list))\n",
    "c=0\n",
    "for i in range(len(predicted_labels_test)):\n",
    "    if predicted_labels_test[i] == test_label_list[i]:\n",
    "        c+=1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P04S0qmZZrAc",
    "outputId": "5eacee9c-e6df-4df4-f07a-15d7df798ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296 296\n"
     ]
    }
   ],
   "source": [
    "c1 = 0\n",
    "c2 = 0\n",
    "for i in range(len(test_label_list)):\n",
    "    if test_label_list[i] == 0:\n",
    "        c1+=1\n",
    "    else:\n",
    "        c2+=1\n",
    "print(c1, c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8SIoFPcKb1TC"
   },
   "source": [
    "### classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TN3-SdxOZrAg",
    "outputId": "435fb2d9-65d3-464a-98c3-43811972ad3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.84      0.75       296\n",
      "           1       0.79      0.59      0.68       296\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       592\n",
      "   macro avg       0.73      0.72      0.71       592\n",
      "weighted avg       0.73      0.72      0.71       592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label_list, predicted_labels_test, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.7162162162162162\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy: ', accuracy_score(test_label_list, predicted_labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-nnVVIAMb7Jc"
   },
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3mAZG25bZrAk"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_label_list, predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NgW1xYnFZrAn"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(mat, labels):\n",
    "    df_cm = pd.DataFrame(mat, index = labels,\n",
    "                  columns = labels)\n",
    "    plt.figure(figsize = (6,4))\n",
    "    sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwlnN_r9ZrAt",
    "outputId": "f2a64e86-9abf-4c1d-c70a-de889505ff9c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, ['0','1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## since there is an imbalance in precision and recall values of both classes.\n",
    "## It may be because of class imbalance. So lets handle class imbalance by imposing penalty to imbalanced class.\n",
    "## we can do this by adding parameter class_weight = {1:3} as class 0 and class 1 is approx 3:1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KOt7kD0JI3mM"
   },
   "source": [
    "# Handling class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15ancJcNZrA1",
    "outputId": "d6e721ae-f6fd-43f6-abc3-c404150c342d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shishir\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "weighted_classifier = svm.SVC(C=1.0, kernel='rbf',class_weight={1:3}).fit(features, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S43EDBxJZrAx",
    "outputId": "0787b849-be26-4015-d587-dab90703f51b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7162162162162162\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ', accuracy_score(test_label_list, predicted_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1geX67TZrA9",
    "outputId": "8de1c3ad-e7f3-498b-d3bd-fd84f81850e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.8223529411764706\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = weighted_classifier.predict(features)\n",
    "print('train accuracy: ', accuracy_score(label_list, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_YMNBioYZrBC",
    "outputId": "677317ec-81d0-4b7c-eda7-67d456e90e2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       296\n",
      "           1       0.72      0.70      0.71       296\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       592\n",
      "   macro avg       0.71      0.71      0.71       592\n",
      "weighted avg       0.71      0.71      0.71       592\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sent_list,test_label_list = read_csv('C:\\\\Users\\\\Shishir\\\\data\\\\SubtaskA_Trial_Test_Labeled.csv')\n",
    "test_sent_list = test_sent_list[1:]\n",
    "test_label_list = test_label_list[1:]\n",
    "test_label_list = np.array([int(label) for label in test_label_list])\n",
    "test_features = get_features(test_sent_list)\n",
    "predicted_labels_test= weighted_classifier.predict(test_features)\n",
    "print(classification_report(test_label_list, predicted_labels_test, target_names=['0', '1']))\n",
    "cm = confusion_matrix(test_label_list, predicted_labels_test)\n",
    "plot_confusion_matrix(cm, ['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab_type": "text",
    "id": "8gCtvyIyZrBJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.714527027027027\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy: ', accuracy_score(test_label_list, predicted_labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## as we can observe that test accuracy after handling class imbalance is almost remains same but per precision and recall has improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOimu1Z3ZrBL"
   },
   "source": [
    "## RNN LSTM IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Po2MZOzMZrBM"
   },
   "outputs": [],
   "source": [
    "# sent_list,label_list\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "# get rid of punctuation\n",
    "# reviews = reviews.lower() # lowercase, standardize\n",
    "sent_list_1 = [sent[1].lower() for sent in sent_list]\n",
    "\n",
    "for i in range(len(sent_list_1)):\n",
    "    sent = sent_list_1[i]\n",
    "    sent = ''.join([c for c in sent if c not in punctuation])\n",
    "    sent_list_1[i] = sent\n",
    "    \n",
    "all_text = ' '.join(sent_list_1)\n",
    "\n",
    "# create a list of words\n",
    "words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5wOFvoOZrBR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3AN2jR3ZrBX"
   },
   "outputs": [],
   "source": [
    "# feel free to use this import \n",
    "from collections import Counter\n",
    "\n",
    "## Build a dictionary that maps words to integers\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "\n",
    "## use the dict to tokenize each review in reviews_split\n",
    "## store the tokenized reviews in reviews_ints\n",
    "sent_ints = []\n",
    "for sent in sent_list_1:\n",
    "    sent_ints.append([vocab_to_int[word] for word in sent.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4gQ-CTNZrBd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "HbR7mflBZrBo",
    "outputId": "6c3989d5-3e68-41d6-ca07-ab63babd1520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words:  10529\n",
      "\n",
      "Tokenized review: \n",
      " [[45, 353, 1093, 245, 94, 33, 1, 207, 219, 245, 820, 10, 100, 24, 20, 845, 420, 870, 4, 1906, 2669, 4, 20, 574, 13, 800, 2, 1, 54, 75, 8, 730, 283, 1046, 2, 165, 1, 2670, 283, 1046, 43, 6, 457]]\n"
     ]
    }
   ],
   "source": [
    "# stats about vocabulary\n",
    "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
    "print()\n",
    "\n",
    "# print tokens in first review\n",
    "print('Tokenized review: \\n', sent_ints[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-DKPHzlZrBv"
   },
   "outputs": [],
   "source": [
    "encoded_labels = label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "DJ2NnV7tZrB0",
    "outputId": "671cd8dd-88c9-4b43-fc3f-75616cf22c6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 13\n",
      "Maximum review length: 343\n"
     ]
    }
   ],
   "source": [
    "# outlier review stats\n",
    "sent_lens = Counter([len(x) for x in sent_ints])\n",
    "print(\"Zero-length reviews: {}\".format(sent_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(sent_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6Ad2D8HJZrB6",
    "outputId": "27dd2df5-e564-497c-aad8-5a126a73b894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500\n"
     ]
    }
   ],
   "source": [
    "# for ii, sent in enumerate(sent_ints):\n",
    "#     if len(sent) == 0:\n",
    "#         print('dvbd')\n",
    "print(len(encoded_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "PLxIly13ZrCB",
    "outputId": "a1c7a8e0-d622-419d-d84b-af07d2e3ca47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews before removing outliers:  8500\n",
      "Number of reviews after removing outliers:  8487\n"
     ]
    }
   ],
   "source": [
    "print('Number of reviews before removing outliers: ', len(sent_ints))\n",
    "\n",
    "## remove any reviews/labels with zero length from the reviews_ints list.\n",
    "\n",
    "# get indices of any reviews with length 0\n",
    "non_zero_idx = [ii for ii, sent in enumerate(sent_ints) if len(sent) != 0]\n",
    "# remove 0-length reviews and their labels\n",
    "sent_ints = [sent_ints[ii] for ii in non_zero_idx]\n",
    "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
    "\n",
    "print('Number of reviews after removing outliers: ', len(sent_ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b80SAXAjZrCI"
   },
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "    print(features.shape)\n",
    "    \n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        val = np.array(row)[:seq_length]\n",
    "#         print(val.shape)\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "        \n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "Z21BjWIzZrCM",
    "outputId": "f40ee5bb-645c-488a-f42d-5f789ab13d2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8487, 200)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation!\n",
    "\n",
    "seq_length = 200\n",
    "\n",
    "features = pad_features(sent_ints, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(features)==len(sent_ints), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 10 values of the first 30 batches \n",
    "print(features[:30,:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "RIpz7HayZrCR",
    "outputId": "9443bb9e-f5fc-45eb-d5ce-0ed1d0b3bca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(7638, 200) \n",
      "Validation set: \t(849, 200)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.9\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
    "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "\n",
    "# test_idx = int(len(remaining_x)*0.5)\n",
    "# val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "# val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "val_x = remaining_x\n",
    "val_y = remaining_y\n",
    "# val_x = val_x[:800]\n",
    "# val_y = val_y[:800]\n",
    "# train_x = train_x[:7600]\n",
    "# train_y = train_y[:7600]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4iHKwJAZrCX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "# test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "# test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "DVnfq9LlZrCa",
    "outputId": "024444b7-459b-4401-b2cd-e5b55fd5435b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 200])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,  ...,     5,   293,   393],\n",
      "        [    0,     0,     0,  ...,  1364,    41, 10262],\n",
      "        [    0,     0,     0,  ...,  1531,     9,  2308],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,    32,  1377,    94],\n",
      "        [    0,     0,     0,  ...,   495,   158,   108],\n",
      "        [    0,     0,     0,  ...,     3,   229,    14]])\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1])\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(valid_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oguKXAAgZrCd",
    "outputId": "24052783-846d-451b-c481-f4c8990e3318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5EvBBA3ZrCg"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_size = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        h = Variable(torch.zeros(self.n_layers, x.size(0), self.hidden_size)) \n",
    "        c = Variable(torch.zeros(self.n_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # embeddings and lstm_out\n",
    "#         x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        \n",
    "#         lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out, _ = self.lstm(embeds, (h, c))\n",
    "  \n",
    "    \n",
    "#         stack up lstm outputs\n",
    "#         lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "#         # dropout and fully-connected layer\n",
    "#         out = self.dropout(lstm_out)\n",
    "#         out = self.fc(out)\n",
    "#         # sigmoid function\n",
    "#         sig_out = self.sig(out)\n",
    "        \n",
    "#         # reshape to be batch_size first\n",
    "#         sig_out = sig_out.view(batch_size, -1)\n",
    "#         sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "#         # return last sigmoid output and hidden state\n",
    "\n",
    "        sig_out = self.fc(lstm_out[:,-1,:])\n",
    "        sig_out = self.sig(sig_out)\n",
    "        return sig_out\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "LkZY4u2ZZrCk",
    "outputId": "857316a7-cfae-4f5e-ffa3-9beb1f4ed989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(10530, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hdQOwjtXZrCq"
   },
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5710
    },
    "colab_type": "code",
    "id": "xnYLjIwIZrCv",
    "outputId": "6855cd62-1a0b-4735-c2b2-c8615f216f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch started:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.2642, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.2374, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.1382, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0826, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0660, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0474, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0411, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0349, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0503, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0441, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0198, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0309, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0368, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0276, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0262, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0210, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0228, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0208, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0227, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0165, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0218, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0122, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0176, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0169, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0086, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0127, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0103, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0127, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0143, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0082, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0127, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0062, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0136, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0037, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0135, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0070, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0112, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0094, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0098, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0064, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0062, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0101, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0078, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0065, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0060, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0112, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0061, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0105, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0066, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0061, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0043, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0080, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0058, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0059, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0066, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0060, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0055, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0064, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0052, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0039, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0035, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0057, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0035, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0050, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0063, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0058, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0063, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0049, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0062, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0041, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0047, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0036, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0028, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0053, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0047, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0037, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0051, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0051, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0047, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0036, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0042, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0036, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0043, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0042, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0029, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0030, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0043, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0053, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0051, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0055, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0048, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0032, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0038, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0040, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0040, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0039, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0037, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0028, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0022, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0036, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0034, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0043, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0030, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0044, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0043, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0024, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0031, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0045, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0047, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0021, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0024, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0036, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0024, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0036, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0023, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0032, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0024, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0023, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0040, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0031, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0031, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0028, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0052, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0022, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0022, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0024, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0028, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0019, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0024, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0021, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0015, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0027, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0019, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0025, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0023, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0025, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0025, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0021, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0043, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0023, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0019, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0025, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0028, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0022, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0017, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([38])) that is different to the input size (torch.Size([38, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.0022, grad_fn=<DivBackward0>)\n",
      "epoch started:  1\n",
      "loss tensor(0.1983, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.1971, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0884, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0712, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0576, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0559, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0568, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0457, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0222, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0145, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0195, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0224, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0129, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0167, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0175, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0188, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0127, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0094, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0087, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0089, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0079, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0092, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0164, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0151, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0116, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0070, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0088, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0062, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0148, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0092, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0051, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0083, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0089, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0063, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0073, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0082, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0115, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0042, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0052, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0055, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0045, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0061, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0079, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0047, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0067, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0038, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0057, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0038, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0040, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0097, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0037, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0037, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0047, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0025, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0044, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0044, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0030, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0033, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0042, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0038, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0025, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0012, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0039, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0056, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0031, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0053, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0013, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0043, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0028, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0032, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0038, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0059, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0032, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0037, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0037, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0021, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0033, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0038, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0043, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0012, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0032, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0045, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0019, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0022, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0021, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0024, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0028, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0037, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0026, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0025, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0038, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0045, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0035, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0025, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0033, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0034, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0028, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0030, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0029, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0026, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0018, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0028, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0015, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0023, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0035, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0013, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0032, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0012, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0038, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0022, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0019, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0019, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0012, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0028, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0021, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0022, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0027, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0019, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0012, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0024, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0019, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0012, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0029, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0014, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0021, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0019, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0016, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0028, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0017, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0010, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0009, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0020, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0011, grad_fn=<DivBackward0>)\n",
      "loss tensor(0.0016, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 2 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 5\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    \n",
    "    print('epoch started: ', e)\n",
    "\n",
    "    total_loss = 0\n",
    "      for i, (inputs, labels) in enumerate(train_loader,0):\n",
    "            counter += 1\n",
    "\n",
    "            output= net(inputs)\n",
    "            loss = criterion(output, labels.float())\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            total_loss+=loss\n",
    "            print('loss',loss/(i+1.0))\n",
    "\n",
    "           # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OeLvQYP9z_Ku"
   },
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), 'gdrive/My Drive/NLP task data/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "YBnpYLlfRjfb",
    "outputId": "686a5e38-de90-4a2d-d17d-12e7ed1e8ca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(10530, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "net.load_state_dict(torch.load('gdrive/My Drive/NLP task data/model.pth'))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVHxBjY1ZrCx"
   },
   "outputs": [],
   "source": [
    "test_sent_list,test_label_list = read_csv('gdrive/My Drive/NLP task data/SubtaskA_Trial_Test_Labeled.csv')\n",
    "test_sent_list = test_sent_list[1:]\n",
    "test_label_list = test_label_list[1:]\n",
    "test_label_list = np.array([int(label) for label in test_label_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBdFz3VXjyqu"
   },
   "outputs": [],
   "source": [
    "main_test_sent_list, main_test_label_list = read_csv('gdrive/My Drive/NLP task data/SubtaskA_EvaluationData.csv')\n",
    "main_test_sent_list = main_test_sent_list\n",
    "main_test_label_list = main_test_label_list\n",
    "# main_test_label_list = np.array([int(label) for label in main_test_label_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "PpqBgVobhcSR",
    "outputId": "2f438111-8ff3-42c7-f9bf-c4d74a9d998c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1310_1',\n",
       "  \"I'm not asking Microsoft to Gives permission like Android so any app can take my data, but don't keep it restricted like iPhone.\"),\n",
       " ('1312_1', 'somewhere between Android and iPhone.'),\n",
       " ('1313_1',\n",
       "  'And in the Windows Store you can flag the App [Requires Trust] for example.'),\n",
       " ('1313_2',\n",
       "  'Many thanks Sameh Hi, As we know, there is a lot of limitations is WP8 OS due the high security in the OS itself which is very good, but some time we need to allow some apps to do extra works, apps which we trust i.e: hotmail app, facebook app, skype app ....'),\n",
       " ('1313_3',\n",
       "  'The idea is that we can develop a regular app and we request our permissions in the manifest, OR the app can ASK FOR TRUST__ more')]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "voRCMlFHktdd",
    "outputId": "1192b49a-f9bc-4e0b-90c6-70a47bf5954c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('9566', 'This would enable live traffic aware apps.'),\n",
       " ('9569',\n",
       "  'Please try other formatting like bold italics shadow to distinguish titles/subtitles from content.'),\n",
       " ('9576',\n",
       "  'Since computers were invented to save time I suggest we be allowed to upload them all in one zip file - using numbering for the file names and the portal could place them in the right order.'),\n",
       " ('9577', 'Allow rearranging if the user wants to change them!'),\n",
       " ('9579',\n",
       "  'Add SIMD instructions for better use of ARM NEON instructions for math and games.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_sent_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OFdFgc4Ck50U",
    "outputId": "8b83c978-ed16-40ff-efff-a1333fb9a01f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "833"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_test_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxGKBM6p3YHM"
   },
   "outputs": [],
   "source": [
    "def tokenize_review(test_review):\n",
    "  \n",
    "    test_review = [test[1].lower() for test in test_review]\n",
    "    for i in range(len(test_review)):\n",
    "        test = test_review[i]\n",
    "        test = ''.join([c for c in test if c not in punctuation])\n",
    "        test_review[i] = test\n",
    "#     print(test_review[:2])\n",
    "    \n",
    "#     test_review = test_review[1].lower() # lowercase\n",
    "    # get rid of punctuation\n",
    "#     test_text = ''.join([c for c in test_review if c not in punctuation])\n",
    "\n",
    "    # splitting by spaces\n",
    "#     test_words = test_text.split()\n",
    "\n",
    "    # tokens\n",
    "    test_ints = []\n",
    "    for test in test_review:\n",
    "      l = []\n",
    "      for word in test.split():\n",
    "        if vocab_to_int.get(word) is not None:\n",
    "          l.append(vocab_to_int[word])\n",
    "      if len(l)>0:\n",
    "        test_ints.append(l)\n",
    "\n",
    "    return test_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFKwEZeM3OmX"
   },
   "outputs": [],
   "source": [
    "test_ints = tokenize_review(test_sent_list)\n",
    "main_test_ints = tokenize_review(main_test_sent_list)\n",
    "# print(test_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "A3Bojwmd350H",
    "outputId": "f009f2b8-c32a-452a-8fb8-baaf283c69a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(592, 200)\n",
      "(833, 200)\n"
     ]
    }
   ],
   "source": [
    "test_features = pad_features(test_ints, seq_length)\n",
    "main_test_features = pad_features(main_test_ints, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "IgkCnQ-l4TuQ",
    "outputId": "c2df838b-dca4-4b9d-dfc9-c81844ddcbb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,   13,   19,  353,  302, 2265,\n",
       "       2075,   32])"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "C_VkrUnC7wo0",
    "outputId": "f46f445a-21a1-441b-cd36-5617e8db1706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([592, 200])\n",
      "torch.Size([833, 200])\n"
     ]
    }
   ],
   "source": [
    "# test conversion to tensor and pass into your model\n",
    "feature_tensor = torch.from_numpy(test_features)\n",
    "print(feature_tensor.size())\n",
    "\n",
    "main_feature_tensor = torch.from_numpy(main_test_features)\n",
    "print(main_feature_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "T_vtNByL-Xu3",
    "outputId": "e3b66280-a4e7-40f4-9950-f9d532b1b307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([833, 200])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "main_test_data = TensorDataset(torch.from_numpy(main_test_features))\n",
    "# main_test_loader = DataLoader(main_test_data, shuffle = False, batch_size=batch_size)\n",
    "# dataiter = iter(main_test_loader)\n",
    "# sample_x= dataiter.next()\n",
    "# print(main_test_data[0])\n",
    "data = torch.from_numpy(main_test_features)\n",
    "print(data.shape)\n",
    "# data = data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-pVFl25-eC0"
   },
   "outputs": [],
   "source": [
    "test_data = TensorDataset(torch.from_numpy(test_features), torch.from_numpy(test_label_list))\n",
    "test_loader = DataLoader(test_data, shuffle = False, batch_size=batch_size)\n",
    "# predict(net, feature_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxFdOMR8oJSC"
   },
   "source": [
    "### code to test on labeled cross validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "l8MySUUlCPm4",
    "outputId": "a4953512-b28e-49c4-ad78-f07c25c9804a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.547\n",
      "Test accuracy: 0.782\n"
     ]
    }
   ],
   "source": [
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "# init hidden state\n",
    "# h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "#     print(inputs)\n",
    "#     print(labels)\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "#     h = tuple([each.data for each in h])\n",
    "\n",
    "#     if(train_on_gpu):\n",
    "#         inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output = net(inputs)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    predicted_labels.append(pred)\n",
    "    actual_labels.append(labels)\n",
    "#     print(predicted_labels)\n",
    "#     print(labels)\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy())\n",
    "#     correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "#     print(num_correct)\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test accuracy is better with RNN LSTM implementation than SVM implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ARh3uvMVI7y"
   },
   "outputs": [],
   "source": [
    "predicted_labels = [p.data.numpy() for p in predicted_labels]\n",
    "actual_labels = [p.data.numpy() for p in actual_labels]\n",
    "\n",
    "# predicted_labels = torch.cat(predicted_labels, 0)\n",
    "# print(predicted_labels)\n",
    "# predicted_labels = predicted_labels.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OeDBGL6ud6Qe"
   },
   "outputs": [],
   "source": [
    "# predicted_labels[:2]\n",
    "predicted_labels = np.concatenate(predicted_labels, axis=0)\n",
    "actual_labels = np.concatenate(actual_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "colab_type": "code",
    "id": "M3l2yxY3Vlst",
    "outputId": "cbab4f30-b945-4359-f4ff-fbdf44d49691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80       296\n",
      "           1       0.85      0.69      0.76       296\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       592\n",
      "   macro avg       0.79      0.78      0.78       592\n",
      "weighted avg       0.79      0.78      0.78       592\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAD4CAYAAACkGY5dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(classification_report(actual_labels, predicted_labels, target_names=['0', '1']))\n",
    "cm = confusion_matrix(actual_labels, predicted_labels)\n",
    "plot_confusion_matrix(cm, ['0','1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation: good f1 score for both classes. It shows that RNN works better than SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_zTuYosFoQ2I"
   },
   "source": [
    "### code to find label of main test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2hiXbtheWYpp"
   },
   "outputs": [],
   "source": [
    "output = net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YYJlUiACggiQ",
    "outputId": "35e5b84e-5fe2-450b-b805-a6fade13c88d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([833, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wJifl91tz3a"
   },
   "outputs": [],
   "source": [
    "pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "# predicted_labels.append(pred).\n",
    "# print(pred)\n",
    "main_pred = pred.data.numpy()\n",
    "main_pred = main_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1Wnum4Jht_gV",
    "outputId": "10d5c993-7da4-4fb6-b226-bec6a10adc24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "833"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cF_Z6yFNyQM0"
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "path = 'gdrive/My Drive/NLP task data/SubtaskA_EvaluationData.csv'\n",
    "with open(path) as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        rows.append(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O2KXVrA_yTqU",
    "outputId": "41834b59-c89b-4b72-afa2-ed5c5841585d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "833"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "uLAZnPMyzT4W",
    "outputId": "ba1a797c-7f4c-4f1e-b00f-8cff416d7ea8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['9566', 'This would enable live traffic aware apps.', 'X'],\n",
       " ['9569',\n",
       "  'Please try other formatting like bold italics shadow to distinguish titles/subtitles from content.',\n",
       "  'X'],\n",
       " ['9576',\n",
       "  'Since computers were invented to save time I suggest we be allowed to upload them all in one zip file - using numbering for the file names and the portal could place them in the right order.',\n",
       "  'X'],\n",
       " ['9577', 'Allow rearranging if the user wants to change them!', 'X'],\n",
       " ['9579',\n",
       "  'Add SIMD instructions for better use of ARM NEON instructions for math and games.',\n",
       "  'X']]"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wJ7M2QL0j0J"
   },
   "outputs": [],
   "source": [
    "for i in range(len(rows)):\n",
    "    rows[i][2] = main_pred[i]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "eAZf8j-J6CDR",
    "outputId": "f12e6300-145e-4c95-8e71-b5e205d7e254"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['9566', 'This would enable live traffic aware apps.', 0],\n",
       " ['9569',\n",
       "  'Please try other formatting like bold italics shadow to distinguish titles/subtitles from content.',\n",
       "  1],\n",
       " ['9576',\n",
       "  'Since computers were invented to save time I suggest we be allowed to upload them all in one zip file - using numbering for the file names and the portal could place them in the right order.',\n",
       "  0],\n",
       " ['9577', 'Allow rearranging if the user wants to change them!', 1],\n",
       " ['9579',\n",
       "  'Add SIMD instructions for better use of ARM NEON instructions for math and games.',\n",
       "  1]]"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_MrGN04r6ESI"
   },
   "outputs": [],
   "source": [
    "with open('shishir_singhal.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B7Aryfpq7N2V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP task.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
